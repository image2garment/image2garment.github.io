<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Image2Garment: Simulation-ready Garments from a Single Image">
  <meta name="keywords" content="Image2Garment, Garment Simulation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Image2Garment: Simulation-ready Garments from a Single Image</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
    .container-construction {
      font-family: Arial, sans-serif;
      color: #333;
      text-align: center;
      background: #fff;
      border: 2px solid #ff9800;
      border-radius: 10px;
      padding: 20px;
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
      width: 80%;
      max-width: 600px;
      font-size: 1.5em;
    }

    .construction-icon {
      font-size: 5em;
      margin: 20px 0;
    }

    @keyframes progress {
      0% {
        width: 0%;
      }

      50% {
        width: 50%;
      }

      100% {
        width: 0%;
      }
    }
  </style>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Image2Garment: Simulation-ready Garment Generation from a Single
              Image</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://selim-emir-can.github.io/">Selim Emir Can</a><sup>*,1</sup>,</span>
              <span class="author-block">
                <a href="https://janackermann.info">Jan Ackermann</a><sup>*,1</sup>,</span>
              <span class="author-block">
                <a href="https://georgenakayama.github.io/">George Nakayama</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://ruofanliu0129.github.io/Resume/">Ruofan Liu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://wutong16.github.io/">Tong Wu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://y-zheng18.github.io/">Yang Zheng</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://hbertiche.github.io/">Hugues Bertiche</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://mlchai.com/">Menglei Chai</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://thabobeeler.com/">Thabo Beeler</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://stanford.edu/~gordonwz/">Gordon Wetzstein</a><sup>1</sup>
              </span>
            </div>

            <!-- <div class="has-text-weight-bold" style="font-size: 1.5rem; margin-top: 0.5rem; margin-bottom: 0.5rem;">
            </div> -->

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Stanford</span>
              <span class="author-block"><sup>2</sup>Google</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv (soon)</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (soon)</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data (soon)</span>
                  </a>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Animation. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <img src="./static/images/teaser.png" alt="Method Teaser" />

          <!-- Interpolating. -->
          <div class="content has-text-justified">
            <p>
              Our method enables generation of simulation-ready garments from a single image.
              We obtain both the garment geometry represented by a 3D mesh and the physical parameters required for
              simulation. With these we can animate the garment in a simulator showing it interacting with the
              environment in a realistic manner. Our prediction is optimization-free and can be computed in seconds.
            </p>
          </div>
        </div>
      </div>

    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>Estimating physically accurate, simulation-ready garments from a single image is challenging due to the
              absence of image-to-physics datasets and the ill-posed nature of this problem. Prior methods either
              require multi-view capture and expensive differentiable simulation or predict only
              garment geometry without the material properties required for realistic simulation.</p>
            <p>We propose a feed-forward framework that sidesteps these limitations by first fine-tuning a
              vision–language model to infer material composition and fabric attributes from real images, and then
              training a light-weight predictor that maps these attributes to the corresponding physical fabric
              parameters using a small dataset of material–physics measurements.</p>
            <p>Our approach introduces two new datasets (FTAG and T2P) and delivers simulation-ready garments from a
              single image without iterative optimization. Experiments show that our estimator achieves superior
              accuracy in material composition estimation and fabric attribute prediction, and by passing them through
              our physics parameter estimator, we further achieve higher fidelity simulations compared to
              state-of-the-art image-to-garment methods.</p>
          </div>
        </div>
      </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Animation. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Method</h2>
          <img src="./static/images/pipeline.png" alt="Method Overview" />

          <!-- Interpolating. -->
          <div class="content has-text-justified">
            <p>
              We first estimate the garment geometry using an off-the-shelf fine-tuned vision-language-model.
              Then, we utilize another vision-language-model trained to predict the material properties of the garments.
              Finally, we use a light-weight predictor to map the estimated garment materials to physical properties of
              a simulator.
            </p>
          </div>
        </div>
      </div>

    </div>
  </section>


  <section class="section" id="comparisons">
    <div class="container is-max-desktop">
      <!-- Qualitative Comparison. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Baseline Comparisons (Simulations)</h2>

          <!-- labels -->
          <div class="comparison-grid">
            <div class="label">Input Frame</div>
            <div class="label">GarmentRecovery* <a href="#ref1">[1]</a></div>
            <div class="label">AIpparel* <a href="#ref2">[2]</a></div>
            <div class="label">ChatGarment* <a href="#ref3">[3]</a></div>
            <div class="label">Image2Garment (ours)</div>
            <div class="label">Ground Truth</div>
          </div>

          <div class="comparison-row">
            <div class="static-container">
              <img class="zoomable" src="figures/input_01.png" alt="Static Input">
            </div>
            <video autoplay loop muted playsinline
              src="videos/baseline1/jumping_jack_v2garment_recovery_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline
              src="videos/baseline1/jumping_jack_v2AIparrel_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline
              src="videos/baseline1/jumping_jack_v2chatgarment_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline
              src="videos/baseline1/jumping_jack_v2ours_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline src="videos/baseline1/jumping_jackgt_rendered_output.mp4"></video>
          </div>

          <div class="comparison-row">
            <div class="static-container">
              <img class="zoomable" src="figures/input_02.png" alt="Static Input">
            </div>
            <video autoplay loop muted playsinline
              src="videos/baseline2/northern_spin_v2garment_recovery_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline
              src="videos/baseline2/northern_spin_v2AIparrel_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline
              src="videos/baseline2/northern_spin_v2chatgarment_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline
              src="videos/baseline2/northern_spin_v2ours_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline
              src="videos/baseline2/northern_spin_v2gt_rendered_output.mp4"></video>
          </div>

          <div class="comparison-row">
            <div class="static-container">
              <img class="zoomable" src="figures/input_03.png" alt="Static Input">
            </div>
            <video autoplay loop muted playsinline
              src="videos/baseline3/joyful_jumpgarment_recovery_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline
              src="videos/baseline3/joyful_jumpAIparrel_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline
              src="videos/baseline3/joyful_jumpchatgarment_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline src="videos/baseline3/joyful_jumpours_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline src="videos/baseline3/joyful_jumpgt_rendered_output.mp4"></video>
          </div>

          <div class="comparison-row">
            <div class="static-container">
              <img class="zoomable" src="figures/input_04.png" alt="Static Input">
            </div>
            <video autoplay loop muted playsinline
              src="videos/baseline4/reaction_hitgarment_recovery_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline
              src="videos/baseline4/reaction_hitAIparrel_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline
              src="videos/baseline4/reaction_hitchatgarment_v1_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline
              src="videos/baseline4/reaction_hitours_v2_rendered_output.mp4"></video>
            <video autoplay loop muted playsinline src="videos/baseline4/reaction_hitgt_v2_rendered_output.mp4"></video>
          </div>
          <h4><em>GarmentRecovery*, AIpparel*, and ChatGarment* use the <u>randomly sampled physical parameters</u>.
              GarmentRecovery* uses the
              only
              published checkpoint.</em></h4>
          <h4><em>Image2Garment uses the <u>estimated physics parameters</u> and the same garment geometry as
              ChatGarment.</em>
          </h4>
        </div>
      </div>
    </div>
  </section>



  <section class="section" id="comparisons-side-by-side">
    <div class="container is-max-desktop">
      <div class="columns is-centered">

        <!-- Left Column: In-the-Wild -->
        <div class="column is-half has-text-centered">
          <h2 class="title is-3">In-the-Wild Comparisons</h2>

          <div class="comparison-grid-3">
            <div class="label">ChatGarment* <a href="#ref3">[3]</a></div>
            <div class="label">Image2Garment</div>
            <div class="label">Ground Truth</div>
          </div>

          <div class="comparison-row-3">
            <video autoplay loop muted playsinline src="videos/wild01/01_wild_chatgarment.mp4"></video>
            <video autoplay loop muted playsinline src="videos/wild01/01_wild_ours.mp4"></video>
            <video autoplay loop muted playsinline src="videos/wild01/01_wild_gt.mp4"></video>
          </div>

          <div class="comparison-row-3">
            <video autoplay loop muted playsinline src="videos/wild02/02_wild_chatgarment.mp4"></video>
            <video autoplay loop muted playsinline src="videos/wild02/02_wild_ours.mp4"></video>
            <video autoplay loop muted playsinline src="videos/wild02/02_wild_gt.mp4"></video>
          </div>

          <div class="comparison-row-3">
            <video autoplay loop muted playsinline src="videos/wild03/03_wild_chatgarment.mp4"></video>
            <video autoplay loop muted playsinline src="videos/wild03/03_wild_ours.mp4"></video>
            <video autoplay loop muted playsinline src="videos/wild03/03_wild_gt.mp4"></video>
          </div>
        </div>

        <!-- Right Column: Ablation Study -->
        <div class="column is-half has-text-centered">
          <h2 class="title is-3">Ablation Study</h2>

          <div class="comparison-grid-3">
            <div class="label">Random Params</div>
            <div class="label">Our Estimated Params</div>
            <div class="label">Ground Truth</div>
          </div>

          <div class="comparison-row-3">
            <video autoplay loop muted playsinline src="videos/ablation1/jumping_random.mp4"></video>
            <video autoplay loop muted playsinline src="videos/ablation1/jumping_estimated.mp4"></video>
            <video autoplay loop muted playsinline src="videos/ablation1/jumping_gt.mp4"></video>
          </div>

          <div class="comparison-row-3">
            <video autoplay loop muted playsinline src="videos/ablation2/northern_random.mp4"></video>
            <video autoplay loop muted playsinline src="videos/ablation2/northern_estimated.mp4"></video>
            <video autoplay loop muted playsinline src="videos/ablation2/northern_gt.mp4"></video>
          </div>

          <div class="comparison-row-3">
            <video autoplay loop muted playsinline src="videos/ablation3/jab_random.mp4"></video>
            <video autoplay loop muted playsinline src="videos/ablation3/jab_estimated.mp4"></video>
            <video autoplay loop muted playsinline src="videos/ablation3/jab_gt.mp4"></video>
          </div>

          <div class="comparison-row-3">
            <video autoplay loop muted playsinline src="videos/ablation4/reaction_hit_random.mp4"></video>
            <video autoplay loop muted playsinline src="videos/ablation4/reaction_hit_estimated.mp4"></video>
            <video autoplay loop muted playsinline src="videos/ablation4/reaction_hit_gt.mp4"></video>
          </div>
        </div>

      </div>
    </div>
  </section>

  <section class="section" id="references">
    <div class="columns is-centered">

      <!-- Left Column: In-the-Wild -->
      <div class="column is-half">
        <h2 class="title is-3">References</h2>
        <div class="reference-list">
          <div class="reference-item" id="ref1">
            <span class="ref-index">[1]</span>
            <span class="ref-text">Li Ren, et al. "Single View Garment Reconstruction Using Diffusion Mapping Via
              Pattern
              Coordinates." <em>Proceedings of the Special Interest Group on Computer Graphics and Interactive
                Techniques
                Conference Conference Papers.</em> 2025.</span>
          </div>

          <div class="reference-item" id="ref2">
            <span class="ref-index">[2]</span>
            <span class="ref-text">Nakayama Kiyohiro, et al. "AIpparel: A Multimodal Foundation Model for Digital
              Garments."
              <em>Proceedings of the Computer Vision and Pattern Recognition Conference.</em> 2025.</span>
          </div>

          <div class="reference-item" id="ref3">
            <span class="ref-index">[3]</span>
            <span class="ref-text">Bian Siyuan, et al. "Chatgarment: Garment estimation, generation and editing via
              large
              language models." <em>Proceedings of the Computer Vision and Pattern Recognition Conference.</em>
              2025.</span>
          </div>
        </div>
      </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTeX entry will be added once available.</code></pre>
    </div>
  </section>


  <footer class="footer">

    <div class="columns is-centered">
      <div class="content">
        <p>
          The website template is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
        </p>
      </div>
    </div>
  </footer>

</body>

</html>